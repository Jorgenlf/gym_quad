{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loads data from tensorboard for given experiments, writes to dict on format:\n",
    "\n",
    "``` {experiment_id : {dfs[\"metric_1\"] : df[\"scenario\", \"timestep\", \"metric_value\"], ... }, ... } ``` \n",
    "\n",
    "2. Plots single-agent training trajectory, color-coded by scenarios. Not used for resultsgen per 03.06\n",
    "\n",
    "3. Plots a multi-agent version of 2. without scenarios\n",
    "\n",
    "4. Plots double-agent training trajectories, side by side view for comparison of the two best agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('axes', labelsize=12)\n",
    "\n",
    "current_cycler = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# Add two additional new colors to the cycler to fit all 9 scenarios\n",
    "current_cycler.append('#66C2A5')\n",
    "current_cycler.append('#FC8D62')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train3d import scenarios \n",
    "scenarios = list(scenarios.keys())\n",
    "scenarios_plotting_names = [\"Line\", \"Easy\", \"Easy Random\", \"Intermediate\", \"Proficient\", \"Advanced\", \"Expert\", \"Proficient Perturbed\", \"Expert Perturbed\"]\n",
    "\n",
    "metrics_paths = [\"2_terminal_metrics/collision_rate\", \n",
    "                 \"2_terminal_metrics/success_rate\",\n",
    "                 \"3_metrics/a_avg_path_progression\",\n",
    "                 \"3_metrics/ep_&_a_avg_total_path_deviance\",\n",
    "                 \"4_quadcopter_state/ep_&_a_avg_speed\"] \n",
    "metrics_plotting_names = [\"Collision Rate\", \"Success Rate\", \"Path Progression\", \"Average Path Deviance [m]\", \"Average Speed [m/s]\"]\n",
    "n_metrics = len(metrics_paths)\n",
    "\n",
    "\n",
    "exp_ids = [32, 10004, 10005, 10007]\n",
    "agent_names = [\"Agent_exp_32\", \"Agent_exp_10004\", \"Agent_exp_10005\", \"Agent_exp_10007\"] #TODO FILL    \n",
    "\n",
    "exp_agents = dict(zip(exp_ids, agent_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./training_traj_plots/\"\n",
    "os.makedirs(base_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centered_subplots(rows,figsize=None):\n",
    "    \n",
    "    grid_dim=max(rows)\n",
    "    grid_shape=(len(rows),2*grid_dim)\n",
    "    \n",
    "    if figsize:\n",
    "        fig = plt.figure(figsize=(figsize))\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(2*grid_dim,3*len(rows)))\n",
    "    \n",
    "    allaxes=[]\n",
    "    \n",
    "    jrow=0\n",
    "    for row in rows:\n",
    "        offset=0\n",
    "        for i in range(row):\n",
    "            if row<grid_dim:\n",
    "                offset =grid_dim-row\n",
    "                \n",
    "            ax_position=(jrow,2*i+offset)\n",
    "            ax = plt.subplot2grid(grid_shape, ax_position, fig=fig,colspan=2)\n",
    "            allaxes.append(ax)\n",
    "            \n",
    "        jrow+=1\n",
    "        \n",
    "    return fig, allaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data from TensorBoard\n",
    "And filter faulty timesteps from paused training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing overlapping timesteps in scenario expert\n",
      "Removing overlapping timesteps in scenario expert\n",
      "Removing overlapping timesteps in scenario expert\n",
      "Removing overlapping timesteps in scenario expert\n",
      "Removing overlapping timesteps in scenario expert\n",
      "Done loading data for experiment 32\n"
     ]
    },
    {
     "ename": "DirectoryDeletedError",
     "evalue": "Directory ../log/LV_VAE_MESH-v0/Experiment 10004/line/tensorboard/PPO_0/ has been permanently deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:88\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_LoadInternal():\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:110\u001b[0m, in \u001b[0;36mDirectoryWatcher._LoadInternal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loader:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_InitializeLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# If it still doesn't exist, there is no data\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:173\u001b[0m, in \u001b[0;36mDirectoryWatcher._InitializeLoader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_InitializeLoader\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 173\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_GetNextPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m path:\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:210\u001b[0m, in \u001b[0;36mDirectoryWatcher._GetNextPath\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the next path to load from.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03mThis function also does the checking for out-of-order writes as it iterates\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m  The next path to load events from, or None if there are no more paths.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    208\u001b[0m paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\n\u001b[0;32m    209\u001b[0m     path\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mio_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mListDirectoryAbsolute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path_filter(path)\n\u001b[0;32m    212\u001b[0m )\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths:\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\io_wrapper.py:78\u001b[0m, in \u001b[0;36mListDirectoryAbsolute\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Yields all files in the given directory.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03mThe paths are absolute.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 78\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:896\u001b[0m, in \u001b[0;36mlistdir\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a list of entries contained within a directory.\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03mThe list is in arbitrary order. It does not contain the special entries \".\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m  errors.NotFoundError if directory doesn't exist\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 896\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_filesystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py:200\u001b[0m, in \u001b[0;36mLocalFileSystem.listdir\u001b[1;34m(self, dirname)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misdir(dirname):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    202\u001b[0m entries \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(compat\u001b[38;5;241m.\u001b[39mas_str_any(dirname))\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Could not find directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../log/LV_VAE_MESH-v0/Experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscenario\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tensorboard/PPO_0/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m event_accumulator \u001b[38;5;241m=\u001b[39m EventAccumulator(log_dir)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mevent_accumulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m events \u001b[38;5;241m=\u001b[39m event_accumulator\u001b[38;5;241m.\u001b[39mScalars(metric)\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m events]\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\event_accumulator.py:343\u001b[0m, in \u001b[0;36mEventAccumulator.Reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Loads all events added since the last call to `Reload`.\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03mIf `Reload` was never called, loads all events in the file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m  The `EventAccumulator`.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator_mutex:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generator\u001b[38;5;241m.\u001b[39mLoad():\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ProcessEvent(event)\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\admin\\.conda\\envs\\c121_quad3D\\lib\\site-packages\\tensorboard\\backend\\event_processing\\directory_watcher.py:92\u001b[0m, in \u001b[0;36mDirectoryWatcher.Load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOpError:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory):\n\u001b[1;32m---> 92\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DirectoryDeletedError(\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m has been permanently deleted\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directory\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;31mDirectoryDeletedError\u001b[0m: Directory ../log/LV_VAE_MESH-v0/Experiment 10004/line/tensorboard/PPO_0/ has been permanently deleted"
     ]
    }
   ],
   "source": [
    "exp_id_to_dfs = {}\n",
    "\n",
    "for exp_id in exp_ids:\n",
    "    dfs = {}\n",
    "\n",
    "    for metric in metrics_paths:\n",
    "        df = pd.DataFrame()\n",
    "        prev_scen_final_timestep = 0\n",
    "        for scenario in scenarios:\n",
    "            # Extract tf events from logs for given scenario-metric combo\n",
    "            log_dir = f\"../log/LV_VAE_MESH-v0/Experiment {exp_id}/{scenario}/tensorboard/PPO_0/\"\n",
    "\n",
    "            event_accumulator = EventAccumulator(log_dir)\n",
    "            event_accumulator.Reload()\n",
    "\n",
    "            events = event_accumulator.Scalars(metric)\n",
    "            x = [x.step for x in events]\n",
    "            y = [x.value for x in events]\n",
    "            \n",
    "            metric_name = metric.split(\"/\")[-1]\n",
    "            df_scen = pd.DataFrame({\"scenario\": scenario, \"timestep\": x, f\"{metric_name}\": y})\n",
    "\n",
    "            # Order by timestep and remove instances with overlapping timesteps, this can happen if training run has been obstructed\n",
    "            df_scen = df_scen.sort_values(\"timestep\")\n",
    "            df_scen = df_scen.drop_duplicates(subset=\"timestep\", keep=\"last\")\n",
    "\n",
    "            # NB timesteps are ordered correctly and no not begin at 0 for each secenario!\n",
    "            \n",
    "            # set prev_scen_final_timestep to the final timestep of the current scenario\n",
    "            if prev_scen_final_timestep > df_scen[\"timestep\"].iloc[0]:\n",
    "                # Rremove instance\n",
    "                print(f\"Removing overlapping timesteps in scenario {scenario}\")\n",
    "                df_scen = df_scen[df_scen[\"timestep\"] > prev_scen_final_timestep]\n",
    "\n",
    "            prev_scen_final_timestep = df_scen[\"timestep\"].iloc[-1]\n",
    "            # Append to the main dataframe\n",
    "            df = pd.concat([df, df_scen])\n",
    "        \n",
    "        dfs[metric_name] = df\n",
    "\n",
    "        # ensure that timesteps is increasing\n",
    "        for i in range(1, len(df)):\n",
    "            if not df[\"timestep\"].iloc[i] > df[\"timestep\"].iloc[i-1]:\n",
    "                print(f\"Error at index {i} in metric: {metric_name}\")\n",
    "                print(df.iloc[i-1:i+1])\n",
    "\n",
    "    exp_id_to_dfs[exp_id] = dfs\n",
    "    print(\"Done loading data for experiment\", exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to be correct exp id\n",
    "single_exp_id = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'single_exp_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve dataframes for the experiment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dfs \u001b[38;5;241m=\u001b[39m exp_id_to_dfs[\u001b[43msingle_exp_id\u001b[49m]\n\u001b[0;32m      4\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(n_metrics, \u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, (metric_name, data) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dfs\u001b[38;5;241m.\u001b[39mitems()):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'single_exp_id' is not defined"
     ]
    }
   ],
   "source": [
    "# Retrieve dataframes for the experiment\n",
    "dfs = exp_id_to_dfs[single_exp_id]\n",
    "\n",
    "fig, ax = plt.subplots(n_metrics, 1, figsize=(10, 20))\n",
    "\n",
    "for j, (metric_name, data) in enumerate(dfs.items()):\n",
    "    lower_bound = min(data[metric_name])\n",
    "    upper_bound = max(data[metric_name])\n",
    "\n",
    "    # Group data by scenario and plot each scenario with different color\n",
    "    for i, scenario in enumerate(scenarios):\n",
    "        scenario_data = data[data[\"scenario\"] == scenario]\n",
    "        ax[j].plot(scenario_data[\"timestep\"], scenario_data[metric_name], zorder=5, linewidth=1.5, color=current_cycler[i])\n",
    "    \n",
    "    # Plot trend\n",
    "    values_smooth = gaussian_filter1d(data[metric_name], sigma=10)\n",
    "    ax[j].plot(data[\"timestep\"], values_smooth, zorder=5, linewidth=2.0, color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "    ylow_fill, yhigh_fill = ax[j].get_ybound()\n",
    "\n",
    "    for k, scenario in enumerate(scenarios):\n",
    "        scenario_data = data[data[\"scenario\"] == scenario]\n",
    "        next_scenario_data = data[data[\"scenario\"] == scenarios[k + 1]] if k + 1 < len(scenarios) else None\n",
    "        last_index_for_fill = scenario_data[\"timestep\"].iloc[-1] if next_scenario_data is None else next_scenario_data[\"timestep\"].iloc[0]\n",
    "        color = \"white\" if k % 2 == 0 else \"gray\"\n",
    "        ax[j].fill_between([scenario_data[\"timestep\"].iloc[0], last_index_for_fill], ylow_fill, yhigh_fill, color=color, alpha=0.25, zorder=1)\n",
    "    \n",
    "    ax[j].set_xlabel(\"Timesteps\") if j == n_metrics - 1 else ax[j].set_xlabel(\"\")\n",
    "    if j < n_metrics - 1:\n",
    "        ax[j].set_xticklabels([])\n",
    "    ax[j].set_ylabel(metrics_plotting_names[j])\n",
    "    ax[j].set_xlim(0, data[\"timestep\"].iloc[-1] + data[\"timestep\"].iloc[0])\n",
    "    ax[j].set_ylim(ylow_fill, yhigh_fill)\n",
    "\n",
    "    # Add upper axis with scenario names if first plot and only ticks else\n",
    "    scenario_text_positions_x = []\n",
    "    upper_ax_ticks = []\n",
    "    for scenario in scenarios:\n",
    "        scenario_data = data[data[\"scenario\"] == scenario]\n",
    "        midpoint = (scenario_data[\"timestep\"].iloc[0] + scenario_data[\"timestep\"].iloc[-1]) // 2\n",
    "        scenario_text_positions_x.append(midpoint)\n",
    "        upper_ax_ticks.append(scenario_data[\"timestep\"].iloc[0])\n",
    "\n",
    "    upper_ax_ticks = upper_ax_ticks[1:]  # Remove first tick\n",
    "    ax_upper = ax[j].twiny()\n",
    "    ax_upper.set_xlim(0, data[\"timestep\"].iloc[-1])\n",
    "    ax_upper.set_xticks(upper_ax_ticks)\n",
    "    ax_upper.grid(True, which='both', linestyle='--', linewidth=0.8, color='gray', alpha=0.3, zorder=2)\n",
    "    ax_upper.set_xticklabels([' ' for _ in range(len(scenarios) - 1)])\n",
    "        \n",
    "    # Align axes\n",
    "    ax_upper.set_xbound(ax[j].get_xbound())\n",
    "\n",
    "    # Increase number of ticks on x-axis to make it more readable\n",
    "    ax[j].xaxis.set_major_locator(plt.MaxNLocator(11))\n",
    "\n",
    "    # If first plot add top right legend describing the colors\n",
    "    legend_elements = [Line2D([0], [0], color=c, lw=2.0, label=label) for c, label in zip(current_cycler[:len(scenarios)], scenarios_plotting_names)]\n",
    "    if j == 0:\n",
    "        ax[j].legend(handles=legend_elements, loc=\"upper right\", fontsize=10, framealpha=1.0, fancybox=True, ncol=3, alignment='center')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0.05)\n",
    "path = f\"{base_path}exp_{single_exp_id}_training_trajs.pdf\"\n",
    "plt.savefig(path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot multiagent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all for now, but this can be changed to only use a subset\n",
    "exp_ids_multi = exp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10004",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve dataframes for the experiment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m exp_id_to_dfs_ \u001b[38;5;241m=\u001b[39m {exp_id: exp_id_to_dfs[exp_id] \u001b[38;5;28;01mfor\u001b[39;00m exp_id \u001b[38;5;129;01min\u001b[39;00m exp_ids_multi}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#fig, ax = plt.subplots(n_metrics, 1, figsize=(10, 20))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m centered_subplots([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m], figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve dataframes for the experiment\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m exp_id_to_dfs_ \u001b[38;5;241m=\u001b[39m {exp_id: \u001b[43mexp_id_to_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp_id\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m exp_id \u001b[38;5;129;01min\u001b[39;00m exp_ids_multi}\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#fig, ax = plt.subplots(n_metrics, 1, figsize=(10, 20))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m centered_subplots([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m], figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m))\n",
      "\u001b[1;31mKeyError\u001b[0m: 10004"
     ]
    }
   ],
   "source": [
    "# Retrieve dataframes for the experiment\n",
    "exp_id_to_dfs_ = {exp_id: exp_id_to_dfs[exp_id] for exp_id in exp_ids_multi}\n",
    "\n",
    "#fig, ax = plt.subplots(n_metrics, 1, figsize=(10, 20))\n",
    "\n",
    "fig, ax = centered_subplots([2, 2, 1], figsize=(16, 16))\n",
    "\n",
    "for i, (exp_id, dfs) in enumerate(exp_id_to_dfs_.items()):\n",
    "    for j, (metric_name, data) in enumerate(dfs.items()):\n",
    "\n",
    "        # Plot values\n",
    "        ax[j].plot(data[\"timestep\"], data[metric_name], zorder=4, linewidth=1, color=current_cycler[i], alpha = 0.25, label=exp_agents[exp_id])\n",
    "        \n",
    "        # Plot trend\n",
    "        values_smooth = gaussian_filter1d(data[metric_name], sigma=15)\n",
    "        ax[j].plot(data[\"timestep\"], values_smooth, zorder=5, linewidth=1.5 , alpha=1, linestyle=\"-\", color=current_cycler[i])\n",
    "\n",
    "\n",
    "        ax[j].set_xlabel(\"Timesteps\")\n",
    "        ax[j].set_ylabel(metrics_plotting_names[j])\n",
    "\n",
    "        # Increase number of ticks on x-axis to make it more readable\n",
    "        ax[j].xaxis.set_major_locator(plt.MaxNLocator(11))\n",
    "\n",
    "        # If first plot add top right legend describing the colors\n",
    "        legend_elements = [Line2D([0], [0], color=c, lw=2.0, label=label) for c, label in zip(current_cycler[:len(agent_names)], agent_names)]\n",
    "        if j == 0:\n",
    "            ax[j].legend(handles=legend_elements, loc=\"upper right\", fontsize=10, framealpha=1.0, fancybox=True, ncol=2, alignment='center')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.15)\n",
    "\n",
    "path = f\"{base_path}multiplot_training_trajs.pdf\"\n",
    "plt.savefig(path, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot two agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The two experiment ids to compare agents from\n",
    "exp_ids_double = [32, 10007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10007",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m exp_id_to_dfs_ \u001b[38;5;241m=\u001b[39m {exp_id: exp_id_to_dfs[exp_id] \u001b[38;5;28;01mfor\u001b[39;00m exp_id \u001b[38;5;129;01min\u001b[39;00m exp_ids_double}\n\u001b[0;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(n_metrics, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m18\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#, sharex=\"col\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# We force the x axes to be equal number of timesteps so that the plots are comparable\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m exp_id_to_dfs_ \u001b[38;5;241m=\u001b[39m {exp_id: \u001b[43mexp_id_to_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp_id\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m exp_id \u001b[38;5;129;01min\u001b[39;00m exp_ids_double}\n\u001b[0;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(n_metrics, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m18\u001b[39m), sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#, sharex=\"col\")\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# We force the x axes to be equal number of timesteps so that the plots are comparable\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 10007"
     ]
    }
   ],
   "source": [
    "exp_id_to_dfs_ = {exp_id: exp_id_to_dfs[exp_id] for exp_id in exp_ids_double}\n",
    "\n",
    "fig, ax = plt.subplots(n_metrics, 2, figsize=(16, 18), sharey=\"row\")#, sharex=\"col\")\n",
    "\n",
    "\n",
    "# We force the x axes to be equal number of timesteps so that the plots are comparable\n",
    "max_timesteps = 0\n",
    "for i, (exp_id, dfs) in enumerate(exp_id_to_dfs_.items()):\n",
    "    max_timesteps = max(max([data[\"timestep\"].iloc[-1] for data in dfs.values()]), max_timesteps)\n",
    "\n",
    "# Find min and max values for each metric to set the y-axis limits\n",
    "min_per_metric = {metric_name: None for metric_name in dfs.keys()}\n",
    "max_per_metric = {metric_name: None for metric_name in dfs.keys()}\n",
    "for dfs in exp_id_to_dfs_.values():\n",
    "    for metric_name, data in dfs.items():\n",
    "        min_per_metric[metric_name] = min(min(data[metric_name]), min_per_metric[metric_name]) if min_per_metric[metric_name] else min(data[metric_name])\n",
    "        max_per_metric[metric_name] = max(max(data[metric_name]), max_per_metric[metric_name]) if max_per_metric[metric_name] else max(data[metric_name])\n",
    "\n",
    "# Pad min and maxs foreach metric by 10% of the range\n",
    "padding = 0.1 # in percentage\n",
    "for metric_name in min_per_metric.keys():\n",
    "    diff = max_per_metric[metric_name] - min_per_metric[metric_name]\n",
    "    min_per_metric[metric_name] -= padding * abs(diff)\n",
    "    max_per_metric[metric_name] += padding * abs(diff)\n",
    "\n",
    "\n",
    "for i, (exp_id, dfs) in enumerate(exp_id_to_dfs_.items()):\n",
    "    ax[0, i].set_title(agent_names[i], fontsize=14, y=1.03)\n",
    "\n",
    "    for j, (metric_name, data) in enumerate(dfs.items()):\n",
    "        # Group data by scenario and plot each scenario with different color\n",
    "        for k, scenario in enumerate(scenarios):\n",
    "            scenario_data = data[data[\"scenario\"] == scenario]\n",
    "            ax[j, i].plot(scenario_data[\"timestep\"], scenario_data[metric_name], zorder=5, linewidth=1, color=current_cycler[k])\n",
    "        \n",
    "        # Plot trend\n",
    "        values_smooth = gaussian_filter1d(data[metric_name], sigma=10)\n",
    "        ax[j, i].plot(data[\"timestep\"], values_smooth, zorder=5, linewidth=2.0, color=\"gray\", alpha=0.5, linestyle=\"--\")\n",
    "\n",
    "        ylow_fill, yhigh_fill = min_per_metric[metric_name], max_per_metric[metric_name] #ax[j, i].get_ybound()\n",
    "\n",
    "        for k, scenario in enumerate(scenarios):\n",
    "            scenario_data = data[data[\"scenario\"] == scenario]\n",
    "            next_scenario_data = data[data[\"scenario\"] == scenarios[k + 1]] if k + 1 < len(scenarios) else None\n",
    "            last_index_for_fill = max_timesteps if next_scenario_data is None else next_scenario_data[\"timestep\"].iloc[0]\n",
    "            color = \"white\" if k % 2 == 0 else \"gray\"\n",
    "            ax[j, i].fill_between([scenario_data[\"timestep\"].iloc[0], last_index_for_fill], ylow_fill, yhigh_fill, color=color, alpha=0.25, zorder=1)\n",
    "        \n",
    "        ax[j, i].set_xlabel(\"Timesteps\") if j == n_metrics - 1 else ax[j, i].set_xlabel(\"\")\n",
    "        if j < n_metrics - 1:\n",
    "            ax[j, i].set_xticklabels([])\n",
    "        if i == 0:\n",
    "            ax[j, i].set_ylabel(metrics_plotting_names[j])\n",
    "        ax[j, i].set_xlim(0, max_timesteps + data[\"timestep\"].iloc[0])\n",
    "        ax[j, i].set_ylim(ylow_fill, yhigh_fill)\n",
    "\n",
    "        # Add upper axis with scenario names if first plot and only ticks else\n",
    "        scenario_text_positions_x = []\n",
    "        upper_ax_ticks = []\n",
    "        for scenario in scenarios:\n",
    "            scenario_data = data[data[\"scenario\"] == scenario]\n",
    "            midpoint = (scenario_data[\"timestep\"].iloc[0] + scenario_data[\"timestep\"].iloc[-1]) // 2\n",
    "            scenario_text_positions_x.append(midpoint)\n",
    "            upper_ax_ticks.append(scenario_data[\"timestep\"].iloc[0])\n",
    "\n",
    "        upper_ax_ticks = upper_ax_ticks[1:]  # Remove first tick\n",
    "        ax_upper = ax[j, i].twiny()\n",
    "        ax_upper.set_xlim(0, max_timesteps)\n",
    "        ax_upper.set_xticks(upper_ax_ticks)\n",
    "        ax_upper.tick_params(direction='in', length=0, width=0, colors='w') # Hide ticks\n",
    "        ax_upper.grid(True, which='both', linestyle='--', linewidth=0.8, color='gray', alpha=0.3, zorder=2)\n",
    "        ax_upper.set_xticklabels([' ' for _ in range(len(scenarios) - 1)])\n",
    "\n",
    "        # Align axes\n",
    "        ax_upper.set_xbound(ax[j, i].get_xbound())\n",
    "\n",
    "        # Increase number of ticks on x-axis to make it more readable\n",
    "        ax[j, i].xaxis.set_major_locator(plt.MaxNLocator(11))\n",
    "\n",
    "        # If final plot add label below x axis describing the colors\n",
    "        legend_elements = [Line2D([0], [0], color=c, lw=2.0, label=label) for c, label in zip(current_cycler[:len(scenarios)], scenarios_plotting_names)]\n",
    "        if j == n_metrics - 1 and i == 0:\n",
    "            ax[j, i].legend(handles=legend_elements, loc=\"upper center\", bbox_to_anchor = (1,-0.2,0,0), fontsize=10, framealpha=1.0, fancybox=True, ncol=3, alignment='center')\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "path = f\"{base_path}exp_{exp_ids_double[0]}_vs_{exp_ids_double[1]}_training_trajs.pdf\"\n",
    "plt.savefig(path, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quad3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
